{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJitTDesXnfb"
      },
      "source": [
        "# Enter Name here: Ryan McCarthy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnOxafExXnfc"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "This process paper is a time for you to discuss the process you took personally to get to the final project. Why did you choose the data you chose? How well did it work for your question? Did you need (or want) to change your question as you evaluated your data more? What provided you with particular difficulties or struggles? How did you overcome those challenges? What parts were the easy parts?\n",
        "\n",
        "This paper should be a minimum of 300 words. It should be turned in via a .ipynb file, so you can demonstrate some of the issues with code, or you can use it to show things you thought were particularly interesting, but might not have found their way into the final project.\n",
        "\n",
        "Think of this as a reflection on the process you went through to get to the final project. You should be familiar with reflections at this point in your Queens career.\n",
        "\n",
        "Begin writing in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why did you choose the data you chose?\n",
        "\n",
        "I chose the \"US Collegiate Sports Dataset\" for my project because I'm a huge fan of the South Carolina Gamecocks football team and other football programs in the Division I Southeast Conference (SEC). I also play Division I lacrosse.\n",
        "\n",
        "I wanted to learn how much football programs contributed to the overall sports revenue at SEC schools in 2019, whether men's lacrosse programs created more revenue at Division I schools than Division II schools in the years 2015 to 2019, and how many women played lacrosse at Division I schools in 2019."
      ],
      "metadata": {
        "id": "eMBbfXNAX9pR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Did you need (or want) to change your question as you evaluated your data more?\n",
        "\n",
        "Although I was able to use the data in the dataset to directly answer my questions, I feel like my questions were a little too specific and the project would have been a little easier if I made them broader.  I really had to think about ways to analyze the data using uniquely different t-tests and ANOVAs required by the assignments in this project, while keeping the tests directly related to answering my questions in a sensible way.\n"
      ],
      "metadata": {
        "id": "djtHJy2bYIDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What provided you with particular difficulties or struggles?\n",
        "\n",
        "If I could do it all over again, I'd look for a dataset that had more obvious independent and dependent variables.  There were times where the assignments in this project required me to come up with a new t-test or ANOVA that made sense relative to my questions.  For example, it was not obvious whether financial investment was independent of, or dependent on, revenue.  Another challenge was coming up with 3 or more independent variables to use as input into an ANOVA.  Although I was able to do it, I feel like it was harder than it should have been.\n",
        "\n",
        "Using GitHub introduced a whole new learning curve as it, along with a good software development tool like Visual Studio, are part of a good code development and management process.\n",
        "\n",
        "I experienced challenges writing query conditions to get the data I needed from dataframes, cleaning that data, making sure that eliminating missing values and NaN values didn't skew the results in unreasonable ways, and getting diagrams to look pretty was tedious and time consuming.\n",
        "\n",
        "For example, sometimes I had to reduce the amount of data retrieved from the Pandas dataset in order to show it in a readable way on a barplot, boxplot or histogram. I also struggled with \"SettingWithCopyWarning\" alerts that were eventually resolved by using the \".copy()\" function to copy data from one dataframe into another.  According to my web research, and especailly https://www.geeksforgeeks.org/how-to-fix-settingwithcopywarning-in-pandas/.\n",
        "\n",
        "- The \"SettingWithCopyWarning\" in pandas alerts the user about potentially unintended behavior when modifying a DataFrame. It arises when pandas isn't sure whether an operation is being performed on a view or a copy of the original DataFrame. Modifying a view will affect the original DataFrame, while modifying a copy will not. This ambiguity can lead to unexpected results if not handled correctly.  The problem is solved by using the \".loc()\" or \".copy()\" functions.\n",
        "\n",
        "Here's some code where I used a condition statement and dataframe \".copy()\" function to extract data from a data set\n",
        "\n",
        "school_names = ['The University of Alabama','University of Florida', 'University of Georgia',\n",
        "                'University of South Carolina-Columbia','The University of Texas at Austin']\n",
        "school_years = 2015, 2016, 2017, 2018, 2019\n",
        "condition = (df_sports['institution_name'].isin(school_names)) & (df_sports['year'].isin(school_years)) & (df_sports['sports'] == 'Football')\n",
        "df_results = df_sports.loc[condition, ['year', 'sports', 'institution_name', 'rev_men', 'total_rev_menwomen']].copy()\n",
        "\n",
        "Here's some sample code where I removed rows where the colummn 'rev_men' had blanks and NaN values\n",
        "\n",
        "df_results = df_results.dropna(subset=['rev_men'])\n",
        "\n",
        "Other time consuming tasks included getting text to show up in the right locations on plots, especially figuring out when I needed to use transAxes.  Here's an example where I plotted a text string using axis coordinates:\n",
        "\n",
        "text_str = f'Football Revenue\\nF-stat: {round(df_anova.statistic, 4)}\\np-value: {round(df_anova.pvalue, 4)}'\n",
        "plt.text(0.02, 0.9, text_str, fontdict={'color': 'blue'}, transform=plt.gca().transAxes)\n"
      ],
      "metadata": {
        "id": "DlXW6K98YnKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How did you overcome those challenges?\n",
        "\n",
        "I researched information, graphs and examples published on the web along with many hours of brute force trial and error.  I also used the suggested sources of Python information recommended in the \"Other resources\" section of the course material, https://canvas.queens.edu/courses/18035/modules/items/787631."
      ],
      "metadata": {
        "id": "fIM4cgTcYxRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What parts were the easy parts?\n",
        "\n",
        "Learning the Python language was pretty easy because of the amount of information and examples that are available on the web.  Using Jupiter Notebooks and Google colab was easy to get the hang of.  Once I had dataframes containing clean data that I wanted to analyze, using the scipy.stats, matplotlib.pyplot and seaborn libraries to perform the statistical analysis and create graphs was pretty straight forward.  Again, there are plenty of examples on the web."
      ],
      "metadata": {
        "id": "5gfZesKpY0M4"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}